{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python37564bit308fc767c2834ccd82281a8640407f24",
      "display_name": "Python 3.7.5 64-bit"
    },
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwayamParida/handwritten-math-exp-recognition/blob/master/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzZIZRy8mj9u",
        "colab_type": "code",
        "outputId": "b9bb8c0a-a729-4fcf-8e8d-d1db58905843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "PROJECT_DIR = '/content/drive/My Drive/cs231n/project'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI85gR0RV1jE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "from skimage import io, feature\n",
        "from sklearn import linear_model, model_selection\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn, optim, utils\n",
        "from torchvision import models, transforms\n",
        "\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36JRp90oV1jT",
        "colab_type": "text"
      },
      "source": [
        "## Atomic Symbol Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZK3jzAVV1jV",
        "colab_type": "text"
      },
      "source": [
        "The atomic symbol dataset is contained in the directory referenced by the relative filepath stored in `ATOMIC_SYMBOL_DATASET_DIR`. The dataset contains a subdirectory per math symbol with the directory name corresponding to the symbol name. Each subdirectory contains JPG images of the handwritten symbols that serve as training examples for that symbol class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsnoAHhlmKvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd drive/My\\ Drive/cs231n/project/\n",
        "!unzip -n data/data.zip -d data/handwritten-symbols"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN31FFF2V1jW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ATOMIC_SYMBOL_DATASET_DIR = os.path.join(PROJECT_DIR, 'data/handwritten-symbols/extracted_images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg0VFvpav9bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_progress(i, num_items):\n",
        "  progress = '%.2f' % (i / num_items * 100)\n",
        "  progress = f'{progress}% done.'\n",
        "  print('\\b' * len(progress), end='')\n",
        "  print(progress, end='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2dOBf5yV1jZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AtomicSymbolDataset(utils.data.Dataset):\n",
        "  def __init__(self, root_dir, max_examples_per_class=None, transform=None):\n",
        "    self.root_dir = root_dir\n",
        "    self.max_examples_per_class = max_examples_per_class\n",
        "    self.transform = transform\n",
        "    self.num_classes = len(os.listdir(self.root_dir))\n",
        "    self.size = 0\n",
        "    self.build_dataset_info()\n",
        "\n",
        "  def build_dataset_info(self):\n",
        "    self.symbols = defaultdict(list)\n",
        "    for i, d in enumerate(os.listdir(self.root_dir)):\n",
        "      symbol_dir = os.path.join(self.root_dir, d)\n",
        "      if not os.path.isdir(symbol_dir): continue\n",
        "      for j, f in enumerate(os.listdir(symbol_dir)):\n",
        "        if not '.jpg' in f: continue\n",
        "        if j >= self.max_examples_per_class: break\n",
        "        self.symbols[d].append(os.path.join(symbol_dir, f))\n",
        "      print_progress(i, self.num_classes)\n",
        "      self.size += len(self.symbols[d])\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    for symbol, imgs in self.symbols.items():\n",
        "      if idx < len(imgs):\n",
        "        img = io.imread(imgs[idx])\n",
        "        if self.transform is not None:\n",
        "          img = self.transform(img)\n",
        "        return (img, symbol)\n",
        "      else:\n",
        "        idx -= len(imgs)\n",
        "    raise IndexError('Index out of bounds')\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBx0JjBxwMGO",
        "colab_type": "code",
        "outputId": "eb1d4d1f-a59d-4652-ff25-f0dc67603e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "symbol_dataset = AtomicSymbolDataset(ATOMIC_SYMBOL_DATASET_DIR, 100)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b0.00% done.\b\b\b\b\b\b\b\b\b\b\b1.22% done.\b\b\b\b\b\b\b\b\b\b\b2.44% done.\b\b\b\b\b\b\b\b\b\b\b3.66% done.\b\b\b\b\b\b\b\b\b\b\b4.88% done.\b\b\b\b\b\b\b\b\b\b\b6.10% done.\b\b\b\b\b\b\b\b\b\b\b7.32% done.\b\b\b\b\b\b\b\b\b\b\b8.54% done.\b\b\b\b\b\b\b\b\b\b\b9.76% done.\b\b\b\b\b\b\b\b\b\b\b\b10.98% done.\b\b\b\b\b\b\b\b\b\b\b\b12.20% done.\b\b\b\b\b\b\b\b\b\b\b\b13.41% done.\b\b\b\b\b\b\b\b\b\b\b\b14.63% done.\b\b\b\b\b\b\b\b\b\b\b\b15.85% done.\b\b\b\b\b\b\b\b\b\b\b\b17.07% done.\b\b\b\b\b\b\b\b\b\b\b\b18.29% done.\b\b\b\b\b\b\b\b\b\b\b\b19.51% done.\b\b\b\b\b\b\b\b\b\b\b\b20.73% done.\b\b\b\b\b\b\b\b\b\b\b\b21.95% done.\b\b\b\b\b\b\b\b\b\b\b\b23.17% done.\b\b\b\b\b\b\b\b\b\b\b\b24.39% done.\b\b\b\b\b\b\b\b\b\b\b\b25.61% done.\b\b\b\b\b\b\b\b\b\b\b\b26.83% done.\b\b\b\b\b\b\b\b\b\b\b\b28.05% done.\b\b\b\b\b\b\b\b\b\b\b\b29.27% done.\b\b\b\b\b\b\b\b\b\b\b\b30.49% done.\b\b\b\b\b\b\b\b\b\b\b\b31.71% done.\b\b\b\b\b\b\b\b\b\b\b\b32.93% done.\b\b\b\b\b\b\b\b\b\b\b\b34.15% done.\b\b\b\b\b\b\b\b\b\b\b\b35.37% done.\b\b\b\b\b\b\b\b\b\b\b\b36.59% done.\b\b\b\b\b\b\b\b\b\b\b\b37.80% done.\b\b\b\b\b\b\b\b\b\b\b\b39.02% done.\b\b\b\b\b\b\b\b\b\b\b\b40.24% done.\b\b\b\b\b\b\b\b\b\b\b\b41.46% done.\b\b\b\b\b\b\b\b\b\b\b\b42.68% done.\b\b\b\b\b\b\b\b\b\b\b\b43.90% done.\b\b\b\b\b\b\b\b\b\b\b\b45.12% done.\b\b\b\b\b\b\b\b\b\b\b\b46.34% done.\b\b\b\b\b\b\b\b\b\b\b\b47.56% done.\b\b\b\b\b\b\b\b\b\b\b\b48.78% done.\b\b\b\b\b\b\b\b\b\b\b\b50.00% done.\b\b\b\b\b\b\b\b\b\b\b\b51.22% done.\b\b\b\b\b\b\b\b\b\b\b\b52.44% done.\b\b\b\b\b\b\b\b\b\b\b\b53.66% done.\b\b\b\b\b\b\b\b\b\b\b\b54.88% done."
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7f20ab58098d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msymbol_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAtomicSymbolDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mATOMIC_SYMBOL_DATASET_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-585cfdb5cd2c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, max_examples_per_class, transform)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild_dataset_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-585cfdb5cd2c>\u001b[0m in \u001b[0;36mbuild_dataset_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0msymbol_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m'.jpg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_examples_per_class\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/drive/My Drive/cs231n/project/data/handwritten-symbols/extracted_images/('"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV-nREOeV1j6",
        "colab_type": "text"
      },
      "source": [
        "Getting a feel for the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSzgDfHjV1j7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_index = np.random.choice(len(symbol_dataset))\n",
        "sample_img, sample_img_label = symbol_dataset[random_index]\n",
        "_ = plt.imshow(sample_img, cmap='Greys_r')\n",
        "print(f'Symbol: {sample_img_label}')\n",
        "print(f'Image dimensions: {sample_img.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hcd8loK12GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Number of examples: {len(symbol_dataset)}')\n",
        "# print(f'Number of training examples: {X_train.shape[0]}')\n",
        "# print(f'Number of testing examples: {X_test.shape[0]}')\n",
        "print(f'Number of classes: {symbol_dataset.num_classes}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDKvB4QUV1ki",
        "colab_type": "text"
      },
      "source": [
        "# Baseline 1 - Symbol Segmentation and Atomic Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YcNQpAnV1kj",
        "colab_type": "text"
      },
      "source": [
        "To establish a baseline for the classification task, we shall develop a rudimentary model that segments each image of a mathematical expression into individual symbols and then feed these symbols to a Softmax classifer that has been trained on the atomic symbols dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNIojJjmV1kk",
        "colab_type": "text"
      },
      "source": [
        "Segmenting expressions into individual symbols"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6xqM9jEV1kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv4ZaRW-V1kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def featurize(X, featurizers=None):\n",
        "  X_feat = []\n",
        "  for ex in X:\n",
        "    if featurizers is None:\n",
        "      x = np.ndarray.flatten(ex)\n",
        "    else:\n",
        "      x = np.concatenate([np.ndarray.flatten(featurizer(ex)) for featurizer in featurizers])\n",
        "    X_feat.append(x)\n",
        "  return np.array(X_feat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxOnapfQ37pR",
        "colab_type": "text"
      },
      "source": [
        "Converting PyTorch Dataset object into 2D Numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZhv6Ij734fZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.empty(shape=(len(symbol_dataset), *symbol_dataset[0][0].shape))\n",
        "y = np.empty(shape=len(symbol_dataset), dtype=np.str)\n",
        "\n",
        "progress = str()\n",
        "for i in range(len(symbol_dataset)):\n",
        "  X[i], y[i] = symbol_dataset[i]\n",
        "  if i % 20 == 0: print_progress(i, len(symbol_dataset))\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rORCwYMiV1ks",
        "colab_type": "text"
      },
      "source": [
        "Training a Softmax classifier on the raw pixels of the atomic symbols dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPuc1m1bV1kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "softmax_classifier = linear_model.LogisticRegression()\n",
        "X_train_feat = featurize(X_train)\n",
        "softmax_classifier.fit(X_train_feat, y_train)\n",
        "\n",
        "train_acc = softmax_classifier.score(X_train_feat, y_train)\n",
        "test_acc = softmax_classifier.score(featurize(X_test), y_test)\n",
        "print(f'Train accuracy: {train_acc}')\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bzw6uO0T46pZ",
        "colab_type": "text"
      },
      "source": [
        "Training the classifier with DAISY feature descriptors instead of raw pixels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-71p_HDO6gAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_feat = featurize(X_train, [feature.daisy])\n",
        "softmax_classifier.fit(featurize(X_train_feat), y_train)\n",
        "\n",
        "train_acc = softmax_classifier.score(X_train_feat, y_train)\n",
        "test_acc = softmax_classifier.score(featurize(X_test, [feature.daisy]), y_test)\n",
        "print(f'Train accuracy: {train_acc}')\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJS4PJA5dIeu",
        "colab_type": "text"
      },
      "source": [
        "Using AlexNet as a feature extractor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd2z78tB6sW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = models.alexnet(pretrained=True)\n",
        "\n",
        "for param in model_ft.parameters():\n",
        "  param.requires_grad = False\n",
        "num_features = model_ft.classifier[6].in_features\n",
        "model_ft.classifier[6] = nn.Linear(num_features, symbol_dataset.num_classes)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft.to(device)\n",
        "\n",
        "print(model_ft)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm0O-MWgoinN",
        "colab_type": "text"
      },
      "source": [
        "Perform image transformations so that dataset images fit AlexNet configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W23g-OloiFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeC6Dr4LpcsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_train_split = [0.8, 0.2]\n",
        "assert(np.sum(test_train_split) == 1.0)\n",
        "\n",
        "symbol_dataset = AtomicSymbolDataset(ATOMIC_SYMBOL_DATASET_DIR, 100, transforms)\n",
        "\n",
        "split_lengths = np.round(np.multiply(test_train_split, len(symbol_dataset)))\n",
        "split_lengths = split_lengths.astype(int)\n",
        "assert(np.sum(split_lengths) == len(symbol_dataset))\n",
        "\n",
        "train_set, test_set = utils.data.random_split(symbol_dataset, split_lengths)\n",
        "train_loader = utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=2)\n",
        "test_loader = utils.data.DataLoader(test_set, batch_size=4, shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPIOeA9IgrDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = alexnet(inputs)\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSCCRdEWmT-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}